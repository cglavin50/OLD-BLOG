<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Terminal</title>
    <link>https://cglavin50.github.io/</link>
    <description>Recent content on Terminal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Apr 2023 00:02:09 -0400</lastBuildDate><atom:link href="https://cglavin50.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Channels</title>
      <link>https://cglavin50.github.io/posts/channels/</link>
      <pubDate>Tue, 18 Apr 2023 00:02:09 -0400</pubDate>
      
      <guid>https://cglavin50.github.io/posts/channels/</guid>
      <description>Intro to Channels in Go As I got a day to work on some Golang projects, I wanted to cover channels in Go. First of all, what are Golang channels and what make them so great? Go is a language known for it&amp;rsquo;s concurrency support, and channels provide an easy way for concurrent goroutines to communicate/send data. Say I have some basic function here:
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;time&amp;#34; ) func main() { results := make(chan int) // created with the make keyword, we are creating a channel to receive integers over go func() { // so some calculations here time.</description>
      <content>&lt;h1 id=&#34;intro-to-channels-in-go&#34;&gt;Intro to Channels in Go&lt;/h1&gt;
&lt;p&gt;As I got a day to work on some Golang projects, I wanted to cover channels in Go. First of all, what are Golang channels and what make them so great? Go is a language known for it&amp;rsquo;s concurrency support, and channels provide an easy way for concurrent goroutines to communicate/send data. Say I have some basic function here:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;package main

import (
    &amp;#34;fmt&amp;#34;
    &amp;#34;time&amp;#34;
)

func main() {
    results := make(chan int) // created with the make keyword, we are creating a channel to receive integers over
    go func() {
        // so some calculations here
        time.Sleep(10 * time.Second)
        results &amp;lt;- computationalResult
    }()

    // perform some concurrent computations here
    localResult := 5
    total := &amp;lt;- results
    total += localResult

    fmt.Println(total)
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this example, we can send off a goroutine to perform some more computationally heavy work, while continuing the flow in our main function. Then, we can wait until the channel receives a value to compute it to our local total, and finish everything. With easy to use syntax, channels allow us to easily send off multiple goroutines, then compile results and/or wait for specific values or signals to proceed through the flow of our code.&lt;/p&gt;
&lt;p&gt;By default, channels are unbuffered in Go. In other words, for each send &lt;code&gt;channel &amp;lt;- &amp;quot;msg1&amp;quot;&lt;/code&gt;, there must be a corresponding receive &lt;code&gt;msgs &amp;lt;- channel&lt;/code&gt;. We can create a buffered channel, that allows us to accept a passed-in amount of values before a corresponding receive, ex &lt;code&gt;results := make(chan int, 4)&lt;/code&gt;, where four ints can be sent over the results channel before a receive must be called.&lt;/p&gt;
&lt;p&gt;Finally, we can use &lt;code&gt;select{}&lt;/code&gt; to synchronize across multiple channels. Like a switch we define multiple cases, and then when a case can be ran, it will execute. If there are multiple available simultaneously, the switch will choose one at random. One example here:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;select {
    case msgs &amp;lt;- msgsChannel:
        fmt.Println(msgs)
    case &amp;lt;- quitChannel:
        fmt.Println(&amp;#34;quit message receieved&amp;#34;)
        return
} 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note: we can also wrap this in an infinte for loop to keep receiving messages until a quit is received, which will then finally exit the program.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Postgre SQL with JS</title>
      <link>https://cglavin50.github.io/posts/crawlerp3/</link>
      <pubDate>Sun, 16 Apr 2023 18:05:45 -0400</pubDate>
      
      <guid>https://cglavin50.github.io/posts/crawlerp3/</guid>
      <description>As outlined in previous posts, PostgreSQL is a great option for storing and managing complex data types in SQL (including working with JSONS), with rich language support. Today I&amp;rsquo;m going to cover how to get a PostgreSQL DB up and running, and how to get it connected to your backend.
PostgreSQL 101 Installation of postgresql (ps) follows your standard linux installation (ex $ sudo apt-get install postgresql). PS will create and run off the &amp;lsquo;postgres&amp;rsquo; user, so you will need to switch to that account when you want to use the service.</description>
      <content>&lt;p&gt;As outlined in previous posts, PostgreSQL is a great option for storing and managing complex data types in SQL (including working with JSONS), with rich language support. Today I&amp;rsquo;m going to cover how to get a PostgreSQL DB up and running, and how to get it connected to your backend.&lt;/p&gt;
&lt;h1 id=&#34;postgresql-101&#34;&gt;PostgreSQL 101&lt;/h1&gt;
&lt;p&gt;Installation of postgresql (ps) follows your standard linux installation (ex &lt;code&gt;$ sudo apt-get install postgresql&lt;/code&gt;). PS will create and run off the &amp;lsquo;postgres&amp;rsquo; user, so you will need to switch to that account when you want to use the service. First, you need to start ps, with &lt;code&gt;$ sudo service postgresql start&lt;/code&gt; (and you will run this to start, stop, and restart the service at any time). PS runs off roles, so the first stop is to create a user with the command &lt;code&gt;$ sudo -u postgres -c &amp;quot;creatuser user1&amp;quot;&lt;/code&gt;. Then, create a corresponding database &lt;code&gt;$ sudo -u postgres -c &amp;quot;createdb user1db&amp;quot;&lt;/code&gt;. Finally, we will connect to the PostgreSQL shell with &lt;code&gt;$ sudo -u postgre psql&lt;/code&gt;, and grant our user permissions on the databse with &lt;code&gt;$ GRANT ALL PRIVILEGES ON DATABSE user1db TO user1;&lt;/code&gt;.
Some useful tips: from within the PostgreSQL shell (psql), you can run commands like &amp;lsquo;\l&amp;rsquo; to list all databases, &amp;lsquo;\c dbname&amp;rsquo; to connect to a database, and &amp;lsquo;\conninfo&amp;rsquo; to see what port a database is running on. Lastly, you can edit the postgreql.conf file to add configurations for features like remote connections, ex appending &amp;rsquo;listen_addresses = &amp;lsquo;*&amp;rsquo;&amp;rsquo; to allow remote users to use your DB.&lt;/p&gt;
&lt;h1 id=&#34;node-postgres-pg&#34;&gt;Node-Postgres (pg)&lt;/h1&gt;
&lt;p&gt;If you are going to build an app, I&amp;rsquo;d recommend following their great &lt;a href=&#34;https://node-postgres.com/&#34;&gt;documentation&lt;/a&gt;. However, here I&amp;rsquo;ll provide a summary and how to get it up and running quickly. First, start with the classic install &lt;code&gt;npm i pg&lt;/code&gt;, and if you work with TypeScript, &lt;code&gt;npm i @types/pg&lt;/code&gt;. From there, make sure you have your imports &lt;code&gt;const { Client } = require(&#39;pg&#39;)&lt;/code&gt; or &lt;code&gt;import { Client } from &#39;pg&#39;&lt;/code&gt;, and declare &lt;code&gt;const client = new Client()&lt;/code&gt;, instantiating a PG Client object, which will provide you with all the basic needs to operate with your database. The API also defines 3 other objects, pg.Pool (groups of clients), pg.Result (returned from a query), and Cursor (used to effectively stream through large result sets).
When you create your client object, you will need to define parameters such as user, password, host, port, database, etc. These values will all default to process variables, (ex user defaults to process.env.PGUSER or process.env.USER), so using this in tandem with the dotenv library works great. From there, all you need to do is call &lt;code&gt;client.connect()&lt;/code&gt; and &lt;code&gt;client.query(&#39;SELECT * AS ...&#39;)&lt;/code&gt;, and you will be up and running!&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>PostgreSQL vs MySQL</title>
      <link>https://cglavin50.github.io/posts/postgresql-vs-mysql/</link>
      <pubDate>Sat, 15 Apr 2023 14:34:52 -0400</pubDate>
      
      <guid>https://cglavin50.github.io/posts/postgresql-vs-mysql/</guid>
      <description>Intro to SQL SQL - Structured Query Language - is a programming langauges that runs relational databases (creating, as well as performing read/writes to the database). SQL stores data as in tables. Tables have columns (field), and rows (records/entries). With an easy to pick up syntax, SQL is a great way to build out a database where you want to be able to quickly access information about records, as well as perform operations/comparisons based on fields of different records.</description>
      <content>&lt;h1 id=&#34;intro-to-sql&#34;&gt;Intro to SQL&lt;/h1&gt;
&lt;p&gt;SQL -  Structured Query Language - is a programming langauges that runs relational databases (creating, as well as performing read/writes to the database). SQL stores data as in tables. Tables have columns (field), and rows (records/entries). With an easy to pick up syntax, SQL is a great way to build out a database where you want to be able to quickly access information about records, as well as perform operations/comparisons based on fields of different records. That said, there are 4 main &amp;ldquo;flavors&amp;rdquo; (or dialects) of SQL: PostgreSQL, SQLite, SQL Server (Microsoft), and MySQL, with MySQL being the most popular version.&lt;/p&gt;
&lt;h2 id=&#34;mysql-vs-postgresql&#34;&gt;MySQL vs PostgreSQL&lt;/h2&gt;
&lt;p&gt;While they are syntactically similar, MySQL doesn&amp;rsquo;t have all the subquery support that Postgres offer, such as not supporting LIMIT or ALL clauses in subqueries. Postgres is fully complaint with SQL-standards, so if you want to use all the commands the SQL has to offer, MySQL may limit you. While both dialects support a good amount of languages, Postgre beats out MySQL significantly in terms of range. One key note is that MySQL has no support for Python, so Python devs should elect for Postgre or SQLite. The last key difference here is speed. MySQL boasts blazing fast reads, however lacks great concurrency support (aside: if you are in a system where many users may be writing to the same critical resources at the same time, wrapping your statements in Transactions guarantee atomicity and consistency). Postgres performs better write operations, handles concurrency better, and has better support with larger, more complicated queries. Overall, a smaller-scale setting with just reads will perform best with MySQL, and more complicated settings will perform better with Postgres. They also run on fundamentally different architectures. MySQL runs on a single process, opening threads for each connection. Postgres will open a new system process for each client connection established, potentially putting a high memory-burden on the server. Postgres has one single storage engine, whereas MySQL has 16 different engines giving it strong performance with specialized use cases. Finally, Postgres is much more feature-rich. It offers JSON support (great when migrating from a NoSQL DB), and has a large variety of data types, combined with support for user-defined types.&lt;/p&gt;
&lt;p&gt;Overall, there are usecases for both. No version is better than the other, rather when constructing your system you should outline your usecase, as well as your infrastructure when deciding which to build with. Most smaller scale (below Enterprise-grade) projects will do just fine with hosting a MySQL server, giving fast reads at a low burden to the processor. If you want complex data-types, NoSQL support, and will have frequent, concurrent writes, Postgres will probably be the way to go.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>LinkedIn WebCrawling in JS Pt.2</title>
      <link>https://cglavin50.github.io/posts/linkedin-webcrawling-in-js-pt.2/</link>
      <pubDate>Fri, 14 Apr 2023 16:08:51 -0400</pubDate>
      
      <guid>https://cglavin50.github.io/posts/linkedin-webcrawling-in-js-pt.2/</guid>
      <description>After making some progress on the backend, I have a couple notes.
Some additional tips for Cheerio The first step of using cheerio is calling cheerio.load(html) as discussed last time, so now I will go into the structure of Cheerio. As I&amp;rsquo;m using TypeScript, I have to be strict with my variable typing, so this should help others in the same boat. cheerio.load(html) returns a CheerioAPI object, which is an interface that allows you to query the HTML.</description>
      <content>&lt;p&gt;After making some progress on the backend, I have a couple notes.&lt;/p&gt;
&lt;h1 id=&#34;some-additional-tips-for-cheerio&#34;&gt;Some additional tips for Cheerio&lt;/h1&gt;
&lt;p&gt;The first step of using cheerio is calling &lt;code&gt;cheerio.load(html)&lt;/code&gt; as discussed last time, so now I will go into the structure of Cheerio. As I&amp;rsquo;m using TypeScript, I have to be strict with my variable typing, so this should help others in the same boat. &lt;code&gt;cheerio.load(html)&lt;/code&gt; returns a CheerioAPI object, which is an interface that allows you to query the HTML. Queries will return Cheerio objects, which are generics, giving you an API to traverse and modify the set returned from the initial query. Cheerio supports 3 different classes (+ Cheerio objects), &lt;strong&gt;Element&lt;/strong&gt;, &lt;strong&gt;Document&lt;/strong&gt;, and &lt;strong&gt;Node&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Element: an HTML element. Attributes name, attribs, children?, type?, returning the name of the tag, an Object mapping attribute names to values, an array of Children nodes, and an enum for Script/Style/Tag.&lt;/li&gt;
&lt;li&gt;Document: the root node of the document (DOMS). It has parent and child nodes, as well as a cloneNode method.&lt;/li&gt;
&lt;li&gt;Node: used to create DOM level 1 structures. Methods and attributes same as Document, just gneeralized&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-does-this-look-like&#34;&gt;What does this look like?&lt;/h2&gt;
&lt;p&gt;In the LinkedIn Job Crawler, I first get the CheerioAPI: &lt;code&gt;const $:cheerio.CheerioAPI = cheerio.load(html);&lt;/code&gt;. Next, I get a Cheerio Object storing List Item elements: &lt;code&gt;const jobsHTML: cheerio.Cheerio&amp;lt;cheerio.Element&amp;gt; = $(&#39;li&#39;);&lt;/code&gt;. From there, queries are easy to write out, for example to find Job titles: &lt;code&gt;const jobTitle:string = $(element).find(&#39;h3.base-search-card__title&#39;).text().trim();&lt;/code&gt;, where &lt;code&gt;.find(tagName.className)&lt;/code&gt; gives us access to tags, then calling &lt;code&gt;.text()&lt;/code&gt; or &lt;code&gt;.attr(attrName)&lt;/code&gt; will allows us to find corresponding information.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>LinkedIn WebCrawling in JS pt.1</title>
      <link>https://cglavin50.github.io/posts/webcrawling-with-cheerio-and-axios/</link>
      <pubDate>Thu, 13 Apr 2023 19:45:11 -0400</pubDate>
      
      <guid>https://cglavin50.github.io/posts/webcrawling-with-cheerio-and-axios/</guid>
      <description>Intro to Web Crawling If you don&amp;rsquo;t know, web crawling (or scraping), refers to using some tool to automate searching through the internet, &amp;lsquo;scraping&amp;rsquo; the content you want and storing it as local files, in a DB, what have you. While there are a ton of great tools for this, I started in TypeScript, using Cheerio and Axios to perform LinkedIn web-crawling. An effective web-crawler will parse through the selected domain, be it LinkedIn, USAToday, or whatever, fetching the HTML of releveant pages and storing them for local use.</description>
      <content>&lt;h1 id=&#34;intro-to-web-crawling&#34;&gt;Intro to Web Crawling&lt;/h1&gt;
&lt;p&gt;If you don&amp;rsquo;t know, web crawling (or scraping), refers to using some tool to automate searching through the internet, &amp;lsquo;scraping&amp;rsquo; the content you want and storing it as local files, in a DB, what have you. While there are a ton of great tools for this, I started in TypeScript, using Cheerio and Axios to perform LinkedIn web-crawling. An effective web-crawler will parse through the selected domain, be it LinkedIn, USAToday, or whatever, fetching the HTML of releveant pages and storing them for local use. To be more selective, the crawler can use some parsing tools to find keywords, or just extract headers, the body, whatever you want. For JS projects, the go to seems to be &lt;strong&gt;Axios&lt;/strong&gt; and &lt;strong&gt;Cheerio&lt;/strong&gt;, for fetching and parsing respectively.&lt;/p&gt;
&lt;h2 id=&#34;fetching-the-content-with-axios&#34;&gt;Fetching the Content with Axios&lt;/h2&gt;
&lt;p&gt;Axios is a simple to use library that allows node.js to make HTTP requests, with automatic serialization to JSON, multipart FormData, and url-encoded for the body. It is &lt;em&gt;isomorphic&lt;/em&gt; (meaning that node and browser can run the same code), and supports the promise API (allowing easy asynchronous functions). In the context of web-scraping, it can be as easy as typing &lt;code&gt;axios.get(url)&lt;/code&gt;, and then reading the response data (don&amp;rsquo;t forget to use &lt;code&gt;.then()&lt;/code&gt; as part of the promise API). The hard part can come with figuring out exactly what URL to use. For LinkedIn, after some messing around I found this format worked best:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=job%20title%20here&amp;amp;location=United%20StatesgeoId=103644278&amp;amp;trk=public_jobs_jobs-search-bar_search-submit&amp;amp;position=1&amp;amp;pageNum=0&amp;amp;start=0&#34;&gt;https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=job%20title%20here&amp;amp;location=United%20StatesgeoId=103644278&amp;amp;trk=public_jobs_jobs-search-bar_search-submit&amp;amp;position=1&amp;amp;pageNum=0&amp;amp;start=0&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;querying-with-cheerio&#34;&gt;Querying with Cheerio&lt;/h3&gt;
&lt;p&gt;Cheerio allows you to make jQuery queries, all you need to do is define a cheerio object with &lt;code&gt;const $ = cheerio.load(response.data)&lt;/code&gt;, where response.data can be exchanged with any HTML code. From there, queries are easy. For LinkedIn, I just found all jobs by using &lt;code&gt;const jobs = $(&#39;li&#39;)&lt;/code&gt;, quering all list-items in the HTML. This is easily generalized, and you can query with selectors with the syntax &lt;code&gt;$(selector)&lt;/code&gt;, finding forms, lists, classes, etc. Cheerio also allows you to insert/edit the HTML, useful for situations where you need to automate filling out forms.&lt;/p&gt;
&lt;h4 id=&#34;to-do&#34;&gt;To do&lt;/h4&gt;
&lt;p&gt;While I&amp;rsquo;ve only just started this project, I hope to finish up a basic backend tomorrow, and which point I&amp;rsquo;ll write a followup for any tips for making your own web-crawler.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Proxying 101 and HTTPS CONNECT</title>
      <link>https://cglavin50.github.io/posts/https-connect/</link>
      <pubDate>Wed, 12 Apr 2023 20:37:16 -0400</pubDate>
      
      <guid>https://cglavin50.github.io/posts/https-connect/</guid>
      <description>HTTP(S) Proxying and HTTPS CONNECT So for my research project I am investigating creating HTTP proxies, and thought I would write my post on how HTTP proxies work, different kinds, and the HTTPS CONNECT method.
Proxying 101 Proxying and tunneling are ways to add user safety when navigating the internet. Specifically, proxying is the use of a &amp;ldquo;server&amp;rdquo; node to handle web requests for the client, and comes in two main types: forward and reverse.</description>
      <content>&lt;h1 id=&#34;https-proxying-and-https-connect&#34;&gt;HTTP(S) Proxying and HTTPS CONNECT&lt;/h1&gt;
&lt;p&gt;So for my research project I am investigating creating HTTP proxies, and thought I would write my post on how HTTP proxies work, different kinds, and the HTTPS CONNECT method.&lt;/p&gt;
&lt;h2 id=&#34;proxying-101&#34;&gt;Proxying 101&lt;/h2&gt;
&lt;p&gt;Proxying and tunneling are ways to add user safety when navigating the internet. Specifically, proxying is the use of a &amp;ldquo;server&amp;rdquo; node to handle web requests for the client, and comes in two main types: forward and reverse.
&lt;strong&gt;Forward proxying&lt;/strong&gt; is when I, the client, send my HTTP request to the server (ex GET some html page from a website), and the server will then make forward the request to the destination. The destination will then send the response to the server, who will forward it back to me. This brings the advantage of hiding/obfuscating my IP address from the internet, however requires trust in the proxy. Proxies can also be monitored as they are public, so frequency analysis attacks are strong, and can often-times be unsafe for the user (lack of adequate data protection, etc). One extreme example of forward proxying is Tor, which on a basic level selects many nodes to server as forward proxies, routing your request through several nodes to give the client a high degree of anonymity.
&lt;strong&gt;Reverse proxying&lt;/strong&gt; is server-side, providing load-balancing and protection to the servers that host content. When a packet is addressed to some IP space, say my website, I can have a front-facing reverse proxy that will receive this request, and then handle distributing it to the proper servers. If I have a large cluster, reverse-proxy nodes can distribute requests equally to minimize burden on any single server, and can cache statically-generated content to give faster responses to requests.&lt;/p&gt;
&lt;h3 id=&#34;http-and-proxying&#34;&gt;HTTP and Proxying&lt;/h3&gt;
&lt;p&gt;The above outlines basic ways to make HTTP request through a forward proxy, simply connect to the proxy, and then send it your GET requests to be forwarded off. However, these are only HTTP requests, and as such have no encryption protection, and if the proxy itself becomes compromised, the proxy now knows everything about the client. If the traffic between the proxy and client is intercepted, there is no protection as we are running basic HTTP. Therefore, the next logical step is&amp;hellip;
&lt;strong&gt;HTTPs Proxying&lt;/strong&gt;. Adding in TLS, the client makes a TLS handshake with the server, encrypting this step of the communication. Next up, the server uses it&amp;rsquo;s own certificate to perform a TLS handshake with the destination, there are two different TLS handshakes for each request. That said, each step of the proxy is encrypted, so there is minimal risk from eavesdroppers on any stage of the connection. However, the proxy server will need to decrypt the response and then re-encrypt to send it back to the client, so the proxy still knows everything and there is a high risk of a MitM attack. How do we get end-to-end encryption?&lt;/p&gt;
&lt;h4 id=&#34;https-connect&#34;&gt;HTTPS CONNECT&lt;/h4&gt;
&lt;p&gt;The &lt;strong&gt;HTTPS CONNECT&lt;/strong&gt; request is what we are looking for. First, the client sends an HTTPS CONNECT request to the server, saying I want to connect to &lt;a href=&#34;https://example.com&#34;&gt;https://example.com&lt;/a&gt;. Then, the server will process this, and start a basic TCP (no ecnryption) request to the destination. After the TCP handshake, the server will send back an HTTP-200 response, indicating that we are good to go. From then on, the client can make continuous requests (GET, PUSH, what have you) to the destination, all with HTTPS. The server doesn&amp;rsquo;t process anything, and instead just performs layer 4 forwarding to forward all received packets over the TCP connection. This avoids MitM attacks, as the only way the proxy server (or a malicious user) can do this is spoof the destination&amp;rsquo;s certificate in the TLS handshake, which we are assuming is not going to happen. Essentially, the client has a direct TLS connection with the destination, with the server simply forwarding things in each direction. The server never knows what is happening, as all communication is encrypted under TLS, and anybody eavesdropping between the server and client will simply see encrypted TCP traffic, unable to even determine where it is going, giving us &lt;em&gt;end-to-end encryption&lt;/em&gt;.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Day 1 of Typescript</title>
      <link>https://cglavin50.github.io/posts/day-1-of-typescript/</link>
      <pubDate>Wed, 12 Apr 2023 00:20:12 -0400</pubDate>
      
      <guid>https://cglavin50.github.io/posts/day-1-of-typescript/</guid>
      <description>Trying out typescript Today was a chaotic day (with interview prep), so didn&amp;rsquo;t do much independent work. That said, I spent some time learning about JavaScript, and investigated popular frameworks (for frontend and backend). I think I&amp;rsquo;ll continue using React for frontend, but interesting in using Meteor and more Node.js for backend, and I intend to switch over to TypeScript.
What is TypeScript (basics) For people who don&amp;rsquo;t know about TypeScript, it&amp;rsquo;s a statically typed (technically optionally) JS, allowing you to get better debugging and in theory make a more sound system.</description>
      <content>&lt;h3 id=&#34;trying-out-typescript&#34;&gt;Trying out typescript&lt;/h3&gt;
&lt;p&gt;Today was a chaotic day (with interview prep), so didn&amp;rsquo;t do much independent work. That said, I spent some time learning about JavaScript, and investigated popular frameworks (for frontend and backend). I think I&amp;rsquo;ll continue using React for frontend, but interesting in using Meteor and more Node.js for backend, and I intend to switch over to TypeScript.&lt;/p&gt;
&lt;h2 id=&#34;what-is-typescript-basics&#34;&gt;What is TypeScript (basics)&lt;/h2&gt;
&lt;p&gt;For people who don&amp;rsquo;t know about TypeScript, it&amp;rsquo;s a statically typed (technically optionally) JS, allowing you to get better debugging and in theory make a more sound system. To be honest, I&amp;rsquo;m new to JS and used to being explicit in variable initiation, so I think it&amp;rsquo;ll help me make more sense of the language. That said, the syntax seems a bit weird to get the hang of, esepcially explicitly defining objects, and union sets seem interesting (basically an enum object) but I&amp;rsquo;m looking forward to diving head first.
Besides that I made some changes to my workstation. I added some plugins to my zsh terminal, and releazed that I was working with files from the Windows file system that was making everything slow. I refactored my file system for dev projects and moved it over into the Linux file system, now everything has been incredibly fast.&lt;/p&gt;
&lt;h1 id=&#34;first-project&#34;&gt;First Project&lt;/h1&gt;
&lt;p&gt;First project, a web crawler with backend of basic TypeScript. I may build out a separate frontend with Typescript React as well, but we&amp;rsquo;ll see after I get this working. It&amp;rsquo;s going to crawl linkedin job postings with passed in keywords, and scrape relevant info (pay, remote, website, etc) into a DB (mongo? Maybe a relational?). Typescript seems a bit annoying syntactically at first, but worth the time. The project itself doesn&amp;rsquo;t seem awful, making continuous GET requests, pulling the html from the response, then using Cheerio to parse and search for passed in args (cheerio uses a JQuery implementation, so I have some references to work off). Thinking about locally storing csv files as they would be easy to manipulate, but likely will use some sort of DB (want more experience here, especially with relational DBs in the cloud). That&amp;rsquo;s all the notes for now, but looking forward to it.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Firebase</title>
      <link>https://cglavin50.github.io/posts/firebase/</link>
      <pubDate>Mon, 10 Apr 2023 19:38:57 -0400</pubDate>
      
      <guid>https://cglavin50.github.io/posts/firebase/</guid>
      <description>Today I learned about Firebase! Today I had some time, so I cleaned up my workstation, learned about deployments, and started a quick little side project involving React and Firebase.
What is Firebase? Firebase is esseentially Google&amp;rsquo;s SDK that allows you to deploy and scale apps, providing an API for everything to user authentication, a non-relational database, ML, and even mobile alerts. With a strong React JS library, I was able to follow a guide and get a basic real-time chat app up and running.</description>
      <content>&lt;h1 id=&#34;today-i-learned-about-firebase&#34;&gt;Today I learned about Firebase!&lt;/h1&gt;
&lt;p&gt;Today I had some time, so I cleaned up my workstation, learned about deployments, and started a quick little side project involving React and Firebase.&lt;/p&gt;
&lt;h2 id=&#34;what-is-firebase&#34;&gt;What is Firebase?&lt;/h2&gt;
&lt;p&gt;Firebase is esseentially Google&amp;rsquo;s SDK that allows you to deploy and scale apps, providing an API for everything to user authentication, a non-relational database, ML, and even mobile alerts. With a strong React JS library, I was able to follow a guide and get a basic real-time chat app up and running. With AWS-like IAM configuration, I was able to create security rules surrounding the DB, easily creating a function to limit only Georgetown users from manipulating the DB (still needed to implement this on the frontend as well), as well as validate input such that only signed in, non-banned (to be implemented soon) users can access.&lt;/p&gt;
&lt;h3 id=&#34;what-did-i-practice&#34;&gt;What did I practice?&lt;/h3&gt;
&lt;p&gt;I was able to get some more React practice under my belt. Hooks and states are becoming more comprehensive, and I was able to use them as well as props to effectively create this app without getting too lost. While in the future I want to try some projects with Typescript to use JS as a OOP-langauge, functional React is starting to make sense to me. I got more practice learning APIs/reading documentation with Firebase, and got to see how it can easily make up a strong backend for any project (for cheap too). While I do enjoy backend-development, this may become my choice for quick and easy deployments for web apps, given the tools for authentication and databases were pretty much 2 mouse-clicks away to get running.
I was able to remember some old JS syntax, with windows alerts for pop-up error messages (will clean this up later), and getting some more practice with React ref&amp;rsquo;s as well.
I also got some deployment practice with Firebase Hosting. Easily combined with Github and NPM, I was able to run npm run build to get production code in the build folder, which then is used from firebase&amp;rsquo;s deploy function to get up and running, even setting up Github actions to automate this process with every PR to the repo. With a free domain as well, Firebase Hosting will definitely be a tool I use in the future for applications. The firebase CLI made the deployment process easy, with just firebase login, init, and deploy to get everything set up.&lt;/p&gt;
&lt;h4 id=&#34;what-next&#34;&gt;What next?&lt;/h4&gt;
&lt;p&gt;Well, I want to clean this app up a bit more and see if I can create an anonymous chat system for Georgetown students. This involves creating a ban scheme (could use ML for sentiment analysis), and I could create mobile alerts as well. While I&amp;rsquo;m about to hit a time-crunch for the next two weeks, I&amp;rsquo;ll definitely come back to this project when I have time. I want to continue practicing my react for web development, and this is as good a place as any to work.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>MongoDB Atlas</title>
      <link>https://cglavin50.github.io/posts/mongodbatlas/</link>
      <pubDate>Sun, 09 Apr 2023 20:23:48 -0400</pubDate>
      
      <guid>https://cglavin50.github.io/posts/mongodbatlas/</guid>
      <description>Today I learned&amp;hellip; As I was crunched for time, my goal for today was to mobilize my ToDoList App project from a local DB to a cloud-based one. While in the future I plan to switch to a relational DB, in my original project I wanted to learn more about APIs, so I picked Mongo to get experience working with a nonSQL DB.
MongoDB Atlas MongoDB offers a cloud-based option called Atlas, which comes with a Hobbyist tiers for new developers.</description>
      <content>&lt;h1 id=&#34;today-i-learned&#34;&gt;Today I learned&amp;hellip;&lt;/h1&gt;
&lt;p&gt;As I was crunched for time, my goal for today was to mobilize my ToDoList App project from a local DB to a cloud-based one. While in the future I plan to switch to a relational DB, in my original project I wanted to learn more about APIs, so I picked Mongo to get experience working with a nonSQL DB.&lt;/p&gt;
&lt;h2 id=&#34;mongodb-atlas&#34;&gt;MongoDB Atlas&lt;/h2&gt;
&lt;p&gt;MongoDB offers a cloud-based option called Atlas, which comes with a Hobbyist tiers for new developers. The layout was essentially the same as MongoDB Compass, where I run my local deployment, with everything running within a project scale. Each project has database deployments same as Compass, and each deployment can be configured as a cloud-cluster. Beyond that, each project has a network scope, defining who can connect to this project, as well as users which define access permissions (read/write on a db deployment basis). As I have the most experience with AWS, I chose to run my cloud deployment for my ToDoList DB over AWS out of the presented options from Atlas.&lt;/p&gt;
&lt;h3 id=&#34;pain-points&#34;&gt;Pain Points&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;ve never managed user/passwords over URLs, so I needed to learn about URL encoding to make sure everything was protected. The MongoDB client implicitly will run a TLS handshake so there&amp;rsquo;s encryption there, but to deal with special characters, I used the URL.QueryString and URL.Values.Encode functions to embed the the authentication into the URI string.
Another pain point I encountered was dealing with my internets subnetting scheme. As I live on-campus, the network I access from leads to tons of issues with permissions, so I tried to debug what range of acceptable IPs would work with Atlas. Starting with 0.0.0.0, I eventually figured out that Georgetown maintains a /16 instead of a /17, which after updating seemed to fix my issues.
One last aside, I also learned how to properly manage cron jobs, and set up a bash script that should backup (ex commit and push) the repos for this blog every day, so I can just create the posts and not worry about commiting and everything before I log off for the day.
All in all this was a busy day with not a ton of time to code, so I didn&amp;rsquo;t run into that many noteworthy topics. Now that I&amp;rsquo;ve set the DB to be able to run independently of the actual web app, I&amp;rsquo;m going to look into creating a Docker image for this whole project.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Intro to Hugo!</title>
      <link>https://cglavin50.github.io/posts/myfirstpost/</link>
      <pubDate>Sat, 08 Apr 2023 15:05:27 -0400</pubDate>
      
      <guid>https://cglavin50.github.io/posts/myfirstpost/</guid>
      <description>This is my first post on this site, so I&amp;rsquo;m going to cover what I&amp;rsquo;ve learned about Hugo.
What is Hugo? Hugo is a web-development framework that runs in Go, translating markdown documents to HTML, adding community-built themes to provide CSS styling. All in all, it gives us a great package to set up and run a static webpage. While there are a ton of options out there (many built on JS), Hugo has a wide variety of tools for developing a more complex site (including API-driven content and customization), as well as incredibly fast build times.</description>
      <content>&lt;p&gt;This is my first post on this site, so I&amp;rsquo;m going to cover what I&amp;rsquo;ve learned about Hugo.&lt;/p&gt;
&lt;h1 id=&#34;what-is-hugo&#34;&gt;What is Hugo?&lt;/h1&gt;
&lt;p&gt;Hugo is a web-development framework that runs in Go, translating markdown documents to HTML, adding community-built themes to provide CSS styling. All in all, it gives us a great package to set up and run a static webpage. While there are a ton of options out there (many built on JS), Hugo has a wide variety of tools for developing a more complex site (including API-driven content and customization), as well as incredibly fast build times. I chose Hugo as I couldn&amp;rsquo;t resist a web-builder framework built in Go, and it&amp;rsquo;s plug-and-play themes made it an easy way to start this project.&lt;/p&gt;
&lt;h2 id=&#34;how-do-i-update-this-site&#34;&gt;How do I update this site?&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;m still learning Hugo, so these are some notes before I forget how to deploy a new post. First of all, I&amp;rsquo;m hosting everything in my &amp;ldquo;blog&amp;rdquo; github repo, however the deployment is the actual GitHub pages repo. Hugo -t terminal builds the site pages with the theme terminal, which then directs all the output to the submodule pages repo. That way, I can run hugo server -t terminal, building the pages and getting a local run to make sure everything looks great and I can commit these changes. I locally installed the theme, so won&amp;rsquo;t worry about updating that (recommendation course of action is through Github actions). Posts are created with hugo new posts/postname, and other pages (ex about, links, etc) are all created/stored in the contents subdirectory. Hugo has set styling for the markdown pages that I&amp;rsquo;m still figuring out, so far now it is a copy-and-paste affair, coupled with the md formatting I already know.&lt;/p&gt;
&lt;h3 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s next?&lt;/h3&gt;
&lt;p&gt;Well, as I plan to do this daily I should likely schedule a cron job for commiting and updating the respective repos. I need to figure out where to locally store images so I can make my about page reflect me, and finish developing out the core of the website (about page, links, portfolio, menu), and keep writing!&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>About</title>
      <link>https://cglavin50.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cglavin50.github.io/about/</guid>
      <description>Who am I? I am an undergraduate at Georgetown University, pursuing a B.S. in Computer Science, and a minor in Mathematics, graduating in May 2024. Passionate about problem-solving, networking, and developing an easy-access internet for all, I love to learn and am always looking to find new tech to dive into.
What do I do? I am currently involved with anti-censorship research involving new network protocols on campus, and am a backend developer who enjoys learning web-dev on the side.</description>
      <content>&lt;h1 id=&#34;who-am-i&#34;&gt;Who am I?&lt;/h1&gt;
&lt;p&gt;I am an undergraduate at Georgetown University, pursuing a B.S. in Computer Science, and a minor in Mathematics, graduating in May 2024. Passionate about problem-solving, networking, and developing an easy-access internet for all, I love to learn and am always looking to find new tech to dive into.&lt;/p&gt;
&lt;h2 id=&#34;what-do-i-do&#34;&gt;What do I do?&lt;/h2&gt;
&lt;p&gt;I am currently involved with anti-censorship research involving new network protocols on campus, and am a backend developer who enjoys learning web-dev on the side. I love to code, and have been diving into Go recently as my language of choice. As a tech nerd, I&amp;rsquo;m also interested in deployments/devops, and in general just love configuring computers.&lt;/p&gt;
&lt;h3 id=&#34;goals&#34;&gt;Goals&lt;/h3&gt;
&lt;p&gt;As I love to learn, I wanted to create this page as a blog post, where I intend to write one article covering something new I learned, every day. That way, I hold myself accountable, and I can use this as a place to refer back to when I want to build off something I remember from a previous review day. I want to grow as a developer, and with this I can trick myself into coding for at least 30 minutes a day, and force myself to find some new tech, language, framework, what-have-you that interests me everyday.&lt;/p&gt;
&lt;h4 id=&#34;links&#34;&gt;Links&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/cooper-glavin-5852351aa/&#34;&gt;LinkedIn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cglavin50&#34;&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
  </channel>
</rss>
